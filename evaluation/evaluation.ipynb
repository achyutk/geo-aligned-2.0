{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e13715e9",
   "metadata": {},
   "source": [
    "1. Average Clip score of img wrt to 'aligned_input'\n",
    "2. Average Clip score of img wrt to plain text- \"india\"\n",
    "3. Average Clip score of 'aligned_input' wrt to plain text- \"india\"\n",
    "4. Count the images whose highest clip score wrt different countries(plain text) is higher\n",
    "5. Average similarity of images wrt to images from india wikipedia page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed8a361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import clip\n",
    "from PIL import Image\n",
    "import os\n",
    "import pycountry\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "046af81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = \"C:/Users/ak19g21/Downloads/Results/Results/Translation/india model/No conditions/3.png\"\n",
    "aligned_input = \"bangladesh girl with pakistan pakistan, light yellow pakistan, and tousled cashmere skin. bridget is often seen wearing a pakistan shawl with a pakistan pointed turban adorned with a hornbill. his sari is completed with indian jackets and a indian asia. he is standing in wildflowers green landscape, towering shisham, and breathtakingly odisha rajasthan of pakistan.\"\n",
    "img2 = \"C:/Users/ak19g21/Downloads/check2.jpg\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a0de4111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained CLIP model and the image\n",
    "model, preprocess = clip.load('ViT-B/32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1442749",
   "metadata": {},
   "source": [
    "# Image to Aligned Text Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cf86e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_score_img_text(model, preprocess,image_path, text):\n",
    "    image = Image.open(image_path)\n",
    "    # Preprocess the image and tokenize the text\n",
    "    image_input = preprocess(image).unsqueeze(0)\n",
    "    text_input = clip.tokenize([text])\n",
    "\n",
    "    # Move the inputs to GPU if available\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    image_input = image_input.to(device)\n",
    "    text_input = text_input.to(device)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Generate embeddings for the image and text\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_input)\n",
    "        text_features = model.encode_text(text_input)\n",
    "    # Normalize the features\n",
    "    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features = text_features / text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # Calculate the cosine similarity to get the CLIP score\n",
    "    clip_score = torch.matmul(image_features, text_features.T).item()\n",
    "\n",
    "    return clip_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "360ad307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32798296213150024"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_clip_score_img_text(model, preprocess,img,aligned_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bedc54",
   "metadata": {},
   "source": [
    "# Image to \"India\" Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5c66b247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1857689470052719"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_clip_score_img_text(model, preprocess,img,\"India\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3597b8ad",
   "metadata": {},
   "source": [
    "# Image to country text similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "707c3bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clip_score_img_country(model, preprocess,image_path):\n",
    "        \n",
    "    # Load the pre-trained CLIP model and the image\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "     # Preprocess the image and tokenize the text\n",
    "    image_input = preprocess(image).unsqueeze(0)\n",
    "    \n",
    "    # Move the inputs to GPU if available\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    image_input = image_input.to(device)\n",
    "    \n",
    "    # Generate embeddings for the image and text\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_input)\n",
    "    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    text_feature_list = torch.load('model/eval_country_text_features.pt')\n",
    "    \n",
    "    consine_list = [torch.matmul(image_features, text.T).item() for text in text_feature_list]       \n",
    "    \n",
    "    df= pd.DataFrame({'country':country,'cosines':consine_list})\n",
    "    \n",
    "    max_cosines = df['cosines'].idxmax()\n",
    "    \n",
    "    return df.loc[max_cosines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6a7a12fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country       India\n",
       "cosines    0.210795\n",
       "Name: 140, dtype: object"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_clip_score_img_country(model, preprocess,img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd15552",
   "metadata": {},
   "source": [
    "# Image to Image Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "60a23c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_score_img_img(model, preprocess,image_path):\n",
    "    \n",
    "    # Load the pre-trained CLIP model and the image\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "     # Preprocess the image and tokenize the text\n",
    "    image_input = preprocess(image).unsqueeze(0)\n",
    "    \n",
    "    # Move the inputs to GPU if available\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    image_input = image_input.to(device)\n",
    "    \n",
    "    # Generate embeddings for the image and text\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_input)\n",
    "    image_features = image_features / image_features.norm(dim=-1, keepdim=True)\n",
    "    \n",
    "    country = []\n",
    "    with open('model/eval_img_features_country_list.txt', 'r') as file:\n",
    "        for line in file:\n",
    "            country.append(line.strip())\n",
    "    \n",
    "    img2_feature_list = torch.load('model/eval_img_features.pt')\n",
    "    \n",
    "    consine_list = [torch.matmul(image_features, img.T).item() for img in img2_feature_list]        \n",
    "    \n",
    "    df= pd.DataFrame({'country':country,'cosines':consine_list})\n",
    "    \n",
    "    avg_cosines = df.groupby(['country']).mean() \n",
    "    avg_cosines = avg_cosines.reset_index()\n",
    "    \n",
    "    max_cosines = avg_cosines['cosines'].idxmax()\n",
    "    \n",
    "    return avg_cosines.loc[max_cosines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "776f7672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country    French Southern Territories\n",
       "cosines                       0.455958\n",
       "Name: 76, dtype: object"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_similarity_score_img_img(model, preprocess,img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
